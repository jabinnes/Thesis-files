{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from config import * #config file with path to input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#defining function to run ariba on different databases and species\n",
    "def aribafn(database, species):\n",
    "    databasepath = workpath.joinpath(\"ARIBA\", database) #create path for database\n",
    "    os.makedirs(databasepath, exist_ok = True)\n",
    "    subprocess.run([\"ariba\", \"getref\", database, os.path.join(databasepath, \"out.\"+database)]) #downloading database\n",
    "    \n",
    "    #preparing database\n",
    "    subprocess.run([\"ariba\", \"prepareref\", \"-f\", os.path.join(databasepath, \"out.\"+database+\".fa\"), \"-m\", os.path.join(databasepath, \"out.\"+database+\".tsv\"), os.path.join(databasepath, database+\".prepareref\")])\n",
    "    \n",
    "    #reading the list of isolate names\n",
    "    namelist = sharepath.joinpath(species+\"_isolates\", species+\"_names.txt\")\n",
    "    table = pd.read_table(namelist, names=[\"Isolate\", \"Genus\", \"Species\", \"Newname\"], index_col=\"Isolate\")\n",
    "    prepareref = workpath.joinpath(\"ARIBA\",database, database+\".prepareref\")\n",
    "    outfile=workpath.joinpath(\"ARIBA\", species+\"_ARIBA\", database) # create path for outfile\n",
    "    os.makedirs(outfile, exist_ok = True)\n",
    "    \n",
    "    #assigning reads and running ariba\n",
    "    reads=readpath.joinpath(\"reads\", species+\"_reads\")\n",
    "    r1_files=glob.glob(os.path.join(reads, \"*_R1*\" ))\n",
    "    count=0\n",
    "    for r1 in r1_files:\n",
    "        print(time.ctime())\n",
    "        start=time.time()\n",
    "        count+=1\n",
    "        r2=r1.replace(\"R1\", \"R2\")\n",
    "        try:\n",
    "            labname=table[\"Newname\"][r1.split(\"/\")[5].split(\"_\")[0]]\n",
    "            #labname=table[\"Newname\"][r1.split(\"/\")[5].split(\"_R\")[0]]\n",
    "            print(count, \"finding resistance genes of\", labname)\n",
    "            subprocess.run([\"ariba\", \"run\", prepareref, r1, r2, os.path.join(outfile,labname)])\n",
    "        except:\n",
    "            print (r1, \"does not exist\")\n",
    "        else:\n",
    "            labname=table[\"Newname\"][r1.split(\"/\")[5].split(\"_\")[0]]\n",
    "            #labname=table[\"Newname\"][r1.split(\"/\")[5].split(\"_R\")[0]]\n",
    "            print(count, \"finding resistance genes of\", labname)\n",
    "            subprocess.run([\"ariba\", \"run\", prepareref, r1, r2, os.path.join(outfile,labname)])            \n",
    "        end=time.time()\n",
    "        print((end-start)/60,\"mins\")\n",
    "        \n",
    "            \n",
    "    # creating summary files for ARIBA output\n",
    "    wdir = outfile\n",
    "    os.chdir(wdir)\n",
    "    !ariba summary out.summary */report.tsv\n",
    "    os.chdir(homepath)\n",
    "    \n",
    "    #removing report.tsv and changing yes and no to 1 and 0 in ariba summary output csv\n",
    "    a_s= pd.read_csv(os.path.join(outfile, \"out.summary.csv\"))\n",
    "    a_s[\"name\"]=a_s[\"name\"].str.split(\"/\").str[0]\n",
    "    a_s=a_s.replace(\"yes\", \"1\")\n",
    "    a_s=a_s.replace(\"no\", \"0\")\n",
    "    a_s = a_s[a_s.columns.drop(list(a_s.filter(regex='colour')))]\n",
    "    a_s.to_csv(os.path.join(outfile, \"out.\"+species+\"_\"+database+\".phandango.csv\"), index=False)\n",
    "\n",
    "\n",
    "    #removing report.tsv from ariba summary output tree\n",
    "    tree=os.path.join(outfile, \"out.summary.phandango.tre\")\n",
    "    new_tree = os.path.join(outfile, \"out.\"+species+\"_\"+database+\".phandango.tre\")\n",
    "    with open(tree) as f:\n",
    "        data=f.read()\n",
    "    \n",
    "    with open(new_tree, \"w\") as f:\n",
    "        f.write(data.replace(\"/report.tsv\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#downloading and preparing mlst reference database\n",
    "workpath_human=os.path.join(workpath, \"ARIBA_human_mlst\")\n",
    "home=\"/home/jabin/research/notebooks/\"\n",
    "os.mkdir(workpath_human)\n",
    "os.chdir(workpath_human)\n",
    "!ariba pubmlstget \"Staphylococcus aureus\" get_mlst --verbose\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running ARIBA_mlst on bovine isolates\n",
    "sbh_mlst=pd.read_csv(os.path.join(paperpath, \"data\", \"sbhmlst.csv\"), index_col=\"Assembly\")\n",
    "bovine_mlst=os.path.join(workpath, \"ARIBA_mlst\")\n",
    "prepareref=os.path.join(bovine_mlst, \"get_mlst\", \"ref_db\")\n",
    "outfile=os.path.join(bovine_mlst, \"bovine_mlst_out\")\n",
    "\n",
    "reads=readpath.joinpath(\"reads\", \"Bovine_processed\")\n",
    "r1_files=glob.glob(os.path.join(reads, \"*_R1*\" ))\n",
    "count=0\n",
    "for r1 in r1_files:\n",
    "    print(time.ctime())\n",
    "    start=time.time()\n",
    "    count+=1\n",
    "    r2=r1.replace(\"R1\", \"R2\")\n",
    "    labname=sbh_mlst[\"newname\"][r1.split(\"/\")[5].split(\"_\")[1]]\n",
    "    print(count, \"finding resistance genes of\", labname)\n",
    "    subprocess.run([\"ariba\", \"run\", prepareref, r1, r2, os.path.join(outfile,labname)])           \n",
    "    end=time.time()\n",
    "    print((end-start)/60,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running ARIBA_mlst on human isolates\n",
    "sbh_mlst=pd.read_csv(os.path.join(paperpath, \"data\", \"sbhmlst.csv\"), index_col=\"Assembly\")\n",
    "human_mlst=os.path.join(workpath, \"ARIBA_human_mlst\")\n",
    "prepareref=os.path.join(human_mlst, \"get_mlst\", \"ref_db\")\n",
    "outfile=os.path.join(human_mlst, \"human_mlst_out\")\n",
    "\n",
    "reads=readpath.joinpath(\"reads\", \"Human_processed\")\n",
    "r1_files=glob.glob(os.path.join(reads, \"*_R1*\" ))\n",
    "count=0\n",
    "for r1 in r1_files:\n",
    "    print(time.ctime())\n",
    "    start=time.time()\n",
    "    count+=1\n",
    "    r2=r1.replace(\"R1\", \"R2\")\n",
    "    labname=sbh_mlst[\"newname\"][r1.split(\"/\")[5].split(\"_\")[1]]\n",
    "    print(count, \"finding resistance genes of\", labname)\n",
    "    subprocess.run([\"ariba\", \"run\", prepareref, r1, r2, os.path.join(outfile,labname)])           \n",
    "    end=time.time()\n",
    "    print((end-start)/60,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removing report.tsv and changing yes and no to 1 and 0 in ariba summary output csv\n",
    "outfile=os.path.join(readpath, \"Comparative\", \"ARIBA\")\n",
    "a_s= pd.read_csv(os.path.join(outfile, \"out_vfdb_full.phandango.csv\"))\n",
    "a_s[\"name\"]=a_s[\"name\"].str.split(\"/\").str[2]\n",
    "a_s=a_s.replace(\"yes\", \"1\")\n",
    "a_s=a_s.replace(\"no\", \"0\")\n",
    "a_s = a_s[a_s.columns.drop(list(a_s.filter(regex='colour')))]\n",
    "a_s.to_csv(os.path.join(outfile, \"out_all_vfdb_full.phandango.csv\"), index=False)\n",
    "\n",
    "\n",
    "#removing report.tsv from ariba summary output tree\n",
    "tree=os.path.join(outfile, \"out_vfdb_full.phandango.tre\")\n",
    "new_tree = os.path.join(outfile, \"out_all_vfdb_full.phandango.tre\")\n",
    "with open(tree) as f:\n",
    "    data=f.read()\n",
    "\n",
    "with open(new_tree, \"w\") as f:\n",
    "    f.write(data.replace(\"/report.tsv\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating summary files for ARIBA output\n",
    "outfile=os.path.join(readpath, \"Comparative\", \"ARIBA\")\n",
    "wdir = outfile\n",
    "os.chdir(wdir)\n",
    "!ariba summary out_vfdb_full *_ARIBA/vfdb_full/*/report.tsv\n",
    "os.chdir(homepath)\n",
    "\n",
    "a_s= pd.read_csv(os.path.join(outfile, \"out_vfdb_full.phandango.csv\"))\n",
    "a_s[\"name\"]=a_s[\"name\"].str.split(\"/\").str[2]\n",
    "a_s=a_s.replace(\"yes\", \"1\")\n",
    "a_s=a_s.replace(\"no\", \"0\")\n",
    "a_s = a_s[a_s.columns.drop(list(a_s.filter(regex='colour')))]\n",
    "a_s.to_csv(os.path.join(outfile, \"out_all_vfdb_full.phandango.csv\"), index=False)\n",
    "\n",
    "\n",
    "#removing report.tsv from ariba summary output tree\n",
    "tree=os.path.join(outfile, \"out_vfdb_full.phandango.tre\")\n",
    "new_tree = os.path.join(outfile, \"out_all_vfdb_full.phandango.tre\")\n",
    "with open(tree) as f:\n",
    "    data=f.read()\n",
    "\n",
    "with open(new_tree, \"w\") as f:\n",
    "    f.write(data.replace(\"/report.tsv\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating dataset for itol tree\n",
    "def itree(database, species, colour)\n",
    "outfile=os.path.join(readpath, \"Comparative\", \"ARIBA\")\n",
    "inputpath= os.path.join(outfile, species+'_ARIBA', database)\n",
    "export_location = os.path.join(outfile, species+\"_ARIBA\", database, species+database+\"_tree.pdf\")\n",
    "oldtree = os.path.join(inputpath, 'out.'+species+\"_\"+database+\".phandango.tre\")\n",
    "tree = os.path.join(inputpath, 'out.'+species+\"_\"+database+\".phandango.tree\")\n",
    "shutil.copy(oldtree, tree)\n",
    "csv_phandango = os.path.join(inputpath, \"out.\"+species+\"_\"+database+\".phandango.csv\")\n",
    "dataset = os.path.join(inputpath, 'binary_'+species+database+\".txt\")\n",
    "import csv\n",
    "field = list(pd.read_csv(csv_phandango, nrows=0))\n",
    "field_shapes = \",\".join([\"1\"] * len(field[1:]))\n",
    "field_labels = \",\".join(field[1:])\n",
    "output=open(dataset, \"w\")\n",
    "output.writelines(\"DATASET_BINARY\"+\"\\n\"+\"\\n\"+\"SEPARATOR COMMA\"+\"\\n\"+\"\\n\"\n",
    "                  +\"DATASET_LABEL\"+\",\"+database+\"_\"+species+\"\\n\"+\"\\n\"+\"#Dataset color\"\n",
    "                  +\"\\n\"+\"COLOR\"+\",\"+color+\"\\n\"+\"\\n\"+\"FIELD_SHAPES\"+\",\"+field_shapes\n",
    "                  +\"\\n\"+\"\\n\"+\"FIELD_LABELS\"+\",\"+field_labels+\"\\n\"+\"\\n\"+\"SHOW_LABELS\"+\",\"\n",
    "                  +\"1\"+\"\\n\"+\"\\n\"+\"DATA\"+\"\\n\"+\"\\n\")\n",
    "\n",
    "with open(csv_phandango, \"r\") as f:\n",
    "    f_csv = csv.reader(f) \n",
    "    headers = next(f_csv) \n",
    "    with open (dataset, \"a\") as output:\n",
    "        for row in f_csv:\n",
    "            output.write(\",\".join(row)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#extracting genes from fasta file and renaming the header to the isolate name using seqkit\n",
    "def extract(database, gene):\n",
    "    mlstdata=pd.read_csv(os.path.join(paperpath, \"data\", \"sbhmlst.csv\"), index_col=\"old_name\")\n",
    "    filename=glob.glob(os.path.join(readpath, \"Comparative\", \"ARIBA\", \"*\", database, \"*\", \"assemblies.fa\"))\n",
    "    homepath=\"/home/jabin/Documents/Bovine_isolates/\"\n",
    "    for n in filename:\n",
    "        labname=mlstdata[\"newname\"][n.split(\"/\")[7]]\n",
    "        with open (os.path.join(homepath, \"individual_genes\", database+\"_\"+gene+\"_genes.fasta\"), \"a\") as f:\n",
    "            ex=subprocess.Popen([\"seqkit\", \"grep\", \"-r\", \"-p\", \"^\"+gene, n], stdout=subprocess.PIPE)\n",
    "            subprocess.Popen([\"seqkit\",\"replace\", \"-p\",\".+\", \"-r\", labname],stdin=ex.stdout, stdout=f)\n",
    "\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract(\"vfdb_full\", \"vWbp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to run ariba summary on different databases and species\n",
    "def aribafn(database, species):\n",
    "    \n",
    "    #reading the list of isolate names\n",
    "    outfile=readpath.joinpath(\"Comparative\",\"ARIBA\", species+\"_ARIBA\", database) # create path for outfile\n",
    "    os.makedirs(outfile, exist_ok = True)\n",
    "                \n",
    "    # creating summary files for ARIBA output\n",
    "    wdir = outfile\n",
    "    os.chdir(wdir)\n",
    "    !ariba summary out.summary */report.tsv\n",
    "    os.chdir(homepath)\n",
    "    \n",
    "    #removing report.tsv and changing yes and no to 1 and 0 in ariba summary output csv\n",
    "    a_s= pd.read_csv(os.path.join(outfile, \"out.summary.csv\"))\n",
    "    a_s[\"name\"]=a_s[\"name\"].str.split(\"/\").str[0]\n",
    "    a_s=a_s.replace(\"yes\", \"1\")\n",
    "    a_s=a_s.replace(\"no\", \"0\")\n",
    "    a_s = a_s[a_s.columns.drop(list(a_s.filter(regex='colour')))]\n",
    "    a_s.to_csv(os.path.join(outfile, \"out.\"+species+\"_\"+database+\".phandango.csv\"), index=False)\n",
    "\n",
    "\n",
    "    #removing report.tsv from ariba summary output tree\n",
    "    tree=os.path.join(outfile, \"out.summary.phandango.tre\")\n",
    "    new_tree = os.path.join(outfile, \"out.\"+species+\"_\"+database+\".phandango.tre\")\n",
    "    with open(tree) as f:\n",
    "        data=f.read()\n",
    "    \n",
    "    with open(new_tree, \"w\") as f:\n",
    "        f.write(data.replace(\"/report.tsv\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aribafn(\"vfdb_core\", \"Bovine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing AST results using seaborn distplot \n",
    "def ast (antibiotic, color):\n",
    "    #input and output files:change path and filename accordingly\n",
    "    AST =  pd.read_excel(os.path.join(sharepath, \"ARIBA\", \"ARIBA_csv\", \"AST test results data for graphs_onefarm.xlsx\"))\n",
    "    outfile = os.path.join(sharepath, \"ARIBA\", \"ARIBA_csv\", drug1+\"_density_AST_onefarm.png\")  \n",
    "    \n",
    "    distfig=sns.distplot(AST[antibiotic], color=color)\n",
    "    distfig.set_title(\"Antibiotic sensitivity test density distribution of \"+ antibiotic)\n",
    "    distfig.set_xlabel(antibiotic+\" diameter(in mm)\")\n",
    "    distfig.set_ylabel('density')\n",
    "    distfig.figure.savefig(outfile, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
